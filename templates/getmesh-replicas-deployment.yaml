apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ template "getmesh.fullname" . }}-replicas
  labels:
    app.kubernetes.io/name: {{ include "getmesh.name" . }}
    helm.sh/chart: {{ include "getmesh.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    app.kubernetes.io/version: {{ .Chart.AppVersion }}
    app.kubernetes.io/component: getmesh-replicas
spec:
  {{- if .Values.getmesh.cluster.enabled }}
  replicas: {{ .Values.getmesh.cluster.replicas }}
  {{- else}}
  replicas: 0
  {{- end}}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "getmesh.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
      app.kubernetes.io/component: getmesh-replicas
  serviceName: "getmesh-replicas"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "getmesh.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
        app.kubernetes.io/component: getmesh-replicas
        app.kubernetes.io/part-of: getmesh-api
    spec:
      terminationGracePeriodSeconds: 15
      initContainers:
      - name: init
        image: alpine
        command: ["/bin/sh", "/config/init-slave-node.sh"]
        securityContext:
          runAsUser: 0
        volumeMounts:
        {{- if and (eq .Values.persistence.nfs.enabled false) (eq .Values.persistence.enabled true) }}
        # in this particuliar case (persistance without nfs) we use getmesh-data-master to store uploads
        - name: getmesh-data-master
        {{- else }}
        - name: getmesh-uploads
        {{- end }}
          mountPath: "/uploads"
          subPath: {{ template "getmesh.fullname.no.override" . }}-uploads
        - name: getmesh-config
          mountPath: /config
        - name: getmesh-data
          mountPath: "/graphdb"
          subPath: "graphdb"
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        command: ["/bin/sh", "/config/startup-slave-node.sh"]
        env:
        {{- range $name, $value := .Values.getmesh.coreEnvironmentVariables }}
         - name: {{ tpl $name $ }}
           value: {{ tpl $value $ | quote }}
        {{- end }}
        {{- range $name, $value := .Values.getmesh.additionalEnvironmentVariables }}
         - name: {{ tpl $name $ }}
           value: {{ tpl $value $ | quote }}
        {{- end }}
        {{- if .Values.oauth2.enabled }}
         - name: MESH_AUTH_OAUTH2_ENABLED
           value: "true"
         - name: MESH_AUTH_OAUTH2_SERVER_CONF_AUTH_SERVER_URL
           value: {{ tpl .Values.oauth2.authServerUrl . | quote }}
        {{- end }}
        ports:
          - name: http
            containerPort: 8080
            protocol: TCP
          - name: monitoring
            containerPort: 8081
            protocol: TCP
          - name: obinary
            containerPort: 2424
            protocol: TCP
          - name: ohttp
            containerPort: 2480
            protocol: TCP
          - name: hazelcast
            containerPort: 5701
            protocol: TCP
        livenessProbe:
          httpGet:
            path: {{ .Values.getmesh.replicas.livenessProbe.httpGet.path | default "/api/v1/" }}
            port: http
          initialDelaySeconds: {{ .Values.getmesh.replicas.livenessProbe.initialDelaySeconds | default 60 }}
          periodSeconds: {{ .Values.getmesh.replicas.livenessProbe.periodSeconds | default 20 }}
          failureThreshold: {{ .Values.getmesh.replicas.livenessProbe.failureThreshold | default 6 }}
        readinessProbe:
          httpGet:
            path: {{ .Values.getmesh.replicas.readinessProbe.httpGet.path | default "/api/v1/admin/status" }}
            port: http
          initialDelaySeconds:  {{ .Values.getmesh.replicas.readinessProbe.initialDelaySeconds | default 45 }}
          periodSeconds:  {{ .Values.getmesh.replicas.readinessProbe.initialDelaySeconds | default 20 }}
          failureThreshold:  {{ .Values.getmesh.replicas.readinessProbe.initialDelaySeconds | default 6 }}
        resources:
{{ toYaml .Values.getmesh.replicas.resources | indent 12 }}
        volumeMounts:
          - name: getmesh-uploads
            mountPath: "/uploads"
            subPath: {{ template "getmesh.fullname.no.override" . }}-uploads
          - name: getmesh-config
            mountPath: "/config"
          - name: getmesh-data
            mountPath: "/graphdb"
            subPath: "graphdb"
      securityContext:
        runAsUser: 1000
        fsGroup: 1000 #user to run used by getmesh official image, if not setted we got some filesystem errors at startup
      volumes:
      - name: getmesh-config
        configMap:
          name: {{ template "getmesh.fullname" . }}-config
      {{- if and (eq .Values.persistence.nfs.enabled true) (eq .Values.persistence.enabled true) }}
      - name: getmesh-uploads
        persistentVolumeClaim:
          claimName: {{ template "getmesh.fullname.no.override" . }}-uploads
      {{- else }}
      - name: getmesh-uploads
        emptyDir: {}
      {{- end }}
      - name: getmesh-data
        emptyDir: {}
      {{- if .Values.getmesh.replicas.tolerations }}
      tolerations:
      {{ toYaml .Values.getmesh.replicas.tolerations | indent 8 }}
      {{- end }}
      {{- if .Values.getmesh.replicas.nodeSelector }}
      nodeSelector:
      {{ toYaml .Values.getmesh.replicas.nodeSelector | indent 8 }}
      {{- end }}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: {{ include "getmesh.name" . }}
                  app.kubernetes.io/instance: {{ .Release.Name }}
